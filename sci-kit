### Where to find what and explanations

basic scikit-learn tutorial
http://blog.kaggle.com/author/kevin-markham/

sklearn.datasets --> example datasets

sklearn.cross_validation - train_test_split  --> validate using tarining and testing split
                         - cross_val_score   --> validate model using cross validation

sklearn.neighbours --> neighbours algorithms
                    -  KNeighboursClassifiers
                    
sklearn.linear_model --> LinearRegression
                    
sklearn.grid_searvh --> 
                      - GridSearchCV
                      - RandomizedSearchCV
                    
sklearn --> scikit learn
          - metrics       --> model evaluation
          

### SYNTAX

X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=2) (split data into training and testing set)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train,y_train)
y_pred = knn.predict(X_test)

scores = cross_val_score(knn{model instance}, X, y, cv=10{cross validation folds}, scoring = 'accuracy') --> gives array with 10 results
scores.mean()
train_scores, test_scores = validation_curve(estimator, X, y, param_name, param_range, cv){cross_validation_plot}
train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv){learning curve to identify under/overfitting}

metrics.accuracy_score(y_test,y_pred) (test accuracy of classification model)

grid = GridSearchCV(knn{model instance}, param_grid{dict of param to change in model and values}, cv=10, scoring='accuracy')
grid.fit(X,y)
grid.grid_scores_[0].parameters             ->  param of this instance
grid.grid_scores_[0].cv_validation_scores   ->  scores of this instance
grid.grid_scores_[0].mean_validation_score  ->  mean score of this instance
grid.best_score_      ->  best accuracy score
grid.best_params_     ->  param with best score
grid.best_estimator_  ->  model object fit with best params
grid.predict          ->  predict values with best model params

rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10{number of random combinations to try}, random_state=5)


from sklearn import tree
dec_tree = tree.DecisionTreeClassifier()
clf.fit(X,y)
y_pred = (X_test)
decison tree --> http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html

from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier()

GBM parameter tuning--> https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/
